{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Tensorflow version 1.10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"Running Tensorflow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are trying to minimize a cost function,\n",
    "\n",
    "$ J = w^2 - 10w + 25 $\n",
    "\n",
    "The correct answer for the value is $5$. Lets see how our learning algorithm figures it out!\n",
    "\n",
    "# Tensorflow 1 convention\n",
    "Tensorflow 1 goes by a **Define and Run** convention. First we define the operations that will take place then initialize variables and execute the session operations.\n",
    "\n",
    "## Define:\n",
    "So, first we will define the operations to take place and the learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Tensorflow variable object of Tensorflow's float32 dtype and initialze with a value of 0 for now\n",
    "w = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "# Defining the cost function that we see above\n",
    "#cost = tf.add(tf.add(w**2, tf.multiply(-10., w)), 25)\n",
    "\n",
    "# A cleaner way of writing the equation\n",
    "cost = w**2 - 10*w + 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our learning algorithm with uses Gradient Descent to minimize the value of 'w'\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Tensorflow 2.0 uses eager execution, so this section below does not apply to Tensorflow >= 2.0.*\n",
    "\n",
    "## Run:\n",
    "This is how we run our computation graphs in Tensorflow 1, we do some setup: initialize variables, initialize a session, then run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() # define: global variable init\n",
    "session = tf.Session()                   # define: session object\n",
    "session.run(init)                        # run: initializing global variables\n",
    "print(session.run(w))                    # run: showing value of w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, that the value of `w` is $0.0$ just like we initialized it. Now we will run gradient descent to find the value of `w` that minimizes the `cost` function $J$.\n",
    "\n",
    "## Training the learning algorithm\n",
    "We run the session on our `train` object which is the Gradient Descent Optimizer trying to minimize the `cost` in terms of `w`.\n",
    "\n",
    "Running one iteration of Gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099999994\n"
     ]
    }
   ],
   "source": [
    "session.run(train)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running 1000 iterations of Gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9999886\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    session.run(train)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our learning algorithm has come quite close to the actual value which is $5$!\n",
    "\n",
    "# Including Training data in our algorithm\n",
    "Till now we minimized a fixed function $J$ with respect to $w$, but in practice in our neural networks the function we will try to minimize will be with respect to our training set $X$.\n",
    "\n",
    "Now let $J$ be,\n",
    "\n",
    "$$ J = w^2 x[0][0] + w x[1][0] + x[2][0] $$\n",
    "\n",
    "Now the $x$ variable (placeholder Tensorflow object) will act like data which controls the coefficient of this quadratic function. This is just another representation of the previous equation, which would have the coefficient values $1, -10$ and $25$.\n",
    "\n",
    "## Define:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to pass into x\n",
    "coeffs = np.array([[1.], [-10.], [25.]])\n",
    "\n",
    "w = tf.Variable(0, dtype=tf.float32)\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[3, 1])\n",
    "\n",
    "cost = x[0][0]*w**2 + x[1][0]*w + x[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099999994\n"
     ]
    }
   ],
   "source": [
    "session.run(train, feed_dict={x: coeffs})\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9999886\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    session.run(train, feed_dict={x: coeffs})\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before our algorithm reached a reasonably accurate value of $w$. But now we can change the value of $x$ and our optimizer will minimize the cost function accoringly!\n",
    "\n",
    "**Note:** this part is idiomatic in Tensorflow 1.\n",
    "```python\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "print(session.run(w))\n",
    "```\n",
    "Alternatively, we can write it using the `with` statement:\n",
    "```python\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    print(session.run(w))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tf_1)",
   "language": "python",
   "name": "tf_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
